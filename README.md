# llama-70b-2bit-gguf
run llama 70b  in 2bit gguf with gpt4all and llama cpp on cpu colab



from
https://huggingface.co/ikawrakow/llama-v2-2bit-gguf/tree/main

thank you ikawrakow
